---
title: 大流量下的反压问题
date: 2017-08-31 20:54:36
tags: [Java,大数据]
categories: 思考
---

最近在梳理公司的大数据处理的流程，运维HBase的同事反馈我们中间件的链路收集日志（类似阿里的鹰眼）给HBase造成的压力最大，问我能不能优化一下。在优化的过程中，梳理了整个链路的反压处理，意识到在流处理，甚至在普通的大流量处理里面，这是一个很重要的问题，结合自己在消息系统，DUBBO服务以及实时处理的经验，在这里总结一下。

#### 反压问题的场景

只要稍微注意一下，反压问题在我们实际的应用中还是很常见的，例如：

1. MQ消息消费：业务消费MQ的消息，处理后，录入到数据库里面。如果数据库出现性能下降，MQ应该降低消费速度
2. Flink实时数据处理：将Flink实时处理的结果写入到HBase。如果HBase出现问题，Flink的处理速度需要降下来
3. 甚至抢红包的业务，也可以看做一个反压的场景：大量流量过来抢红包，数据库IO出现瓶颈，那么，就应该减少放过来的流量
4. 等等

总体来说，反压的场景可以归为两类：

* 单机反压
* 分布式反压

下面就两个场景分开讲一下。

#### 单机反压

处理单机反压，一般借助于下面两个思路：

1. 队列
2. 调度线程池

队列的应用场景，一般是接收用户请求，接收异步消息等等，我们统称为异步task，如下图：

![](/images/middleware/pressure-01.png)

一个典型的生产者－消费者队列，在反压的场景下，很实用。

另外一个在单机的场景下，处理反压问题的就是调度线程池。我们通过线程池调度一个作业，然后，根据外部条件（例如，队列的大小）来动态修改调度的延迟时间，简化的处理代码如下：

```
private class Task implements Runnable {
    @Override
    public void run() {
        int delay = Constants.DEFAULT_DELAY_TIME;
        try {
            delay = doWork();
        } finally {
            if (delay == -1) {
                //stop
            } else {
                PULL_WORKER.schedule(this, delay, TimeUnit.MILLISECONDS);
            }
        }
    }
}
```

上面模型的一个关键在于，线程池的调度不是以固定的速率进行，而是通过每次执行业务逻辑后得到一个反馈，进而影响到任务的调度。





